# Token Reduction Rules

When interacting with LLM backends, prioritize token efficiency.

## 1. Concise Communication
- Always strive to make prompts and responses as direct and concise as possible.
- Avoid unnecessary words, verbose phrasing, or complex sentence structures.

## 2. Context Management
- Proactively summarize older parts of the conversation history to manage the context window.
- Identify and condense less critical information from earlier interactions.
- Prioritize essential context for the current task.
